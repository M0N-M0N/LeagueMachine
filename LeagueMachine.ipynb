{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-27T14:57:47.407534Z",
     "start_time": "2024-08-27T14:57:39.198330Z"
    }
   },
   "source": [
    "import os\n",
    "import pprint\n",
    "import re\n",
    "from textwrap import wrap\n",
    "import timeit\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "import supervision as sv\n",
    "from datetime import datetime\n",
    "\n",
    "import llama38b as llm\n",
    "import easyocr\n",
    "\n",
    "import sys\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "#set device to gpu\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.set_device(0)\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:57:47.418736Z",
     "start_time": "2024-08-27T14:57:47.408546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#from stasck overflow https://stackoverflow.com/questions/14134892/convert-image-from-pil-to-opencv-format\n",
    "def toImgOpenCV(imgPIL): # Conver imgPIL to imgOpenCV\n",
    "    i = np.array(imgPIL) # After mapping from PIL to numpy : [R,G,B,A]\n",
    "    # numpy Image Channel system: [B,G,R,A]\n",
    "    red = i[:,:,0].copy(); i[:,:,0] = i[:,:,2].copy(); i[:,:,2] = red;\n",
    "    return i;\n",
    "\n",
    "def toImgPIL(imgOpenCV): return Image.fromarray(cv2.cvtColor(imgOpenCV, cv2.COLOR_BGR2RGB));\n",
    "\n",
    "\n",
    "def add_text_bubble(texts, font_size=24, max_width=400):\n",
    "    img = Image.open(img_path)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    font = ImageFont.truetype(font_path, size=font_size)\n",
    "\n",
    "    # find text size\n",
    "    text_bbox = draw.textbbox((0, 0), texts, font=font)\n",
    "\n",
    "    # find bubble size\n",
    "    bubble_width = min(max_width, text_bbox[2] - text_bbox[0] + 20)\n",
    "    # Add padding\n",
    "    bubble_height = text_bbox[3] - text_bbox[1] + 20\n",
    "\n",
    "    # text position by anchor\n",
    "    x, y, y2 = 40,20, 0\n",
    "\n",
    "    # Draw the text bubble\n",
    "    draw.rectangle([x, y, x + bubble_width, y + bubble_height], width=0)\n",
    "    draw.text((x + 10, y + 10), texts, font=font)\n",
    "\n",
    "    return toImgOpenCV(img)\n",
    "\n",
    "def process_frame(frame: np.ndarray, index: int, position) -> np.ndarray:\n",
    "    global is_frame, text_bubble, advice_timer, show_advice, resource_dict, frame_interval\n",
    "    is_analysed = False\n",
    "    # index = 900\n",
    "    if index%frame_interval == 0 and index != 0:\n",
    "        is_frame = True\n",
    "\n",
    "    if is_frame:\n",
    "        # print(\"is_frame\", index)\n",
    "        resframe = frame.copy()\n",
    "        results = model(frame, imgsz=1280)[0]\n",
    "        detections = sv.Detections.from_ultralytics(results)\n",
    "        detections = byte_tracker.update_with_detections(detections)\n",
    "        labels = [\n",
    "            f\"#{detection[-2]} {model.model.names[detection[-3]]} {detection[-4]:0.2f}\"\n",
    "            if len(detection) >= 5 else \"Invalid detection\"\n",
    "            for detection in detections\n",
    "        ]\n",
    "\n",
    "        resframe = box_annotator.annotate(scene=resframe, detections=detections)\n",
    "        resframe = label_annotator.annotate(scene=resframe, detections=detections, labels=labels)\n",
    "        resframe = trace_annotator.annotate(scene=resframe, detections=detections)\n",
    "        resources = read_resources(resframe, detections)\n",
    "\n",
    "        for resource in resources:\n",
    "            if resource in resource_dict.keys():\n",
    "                if re.match(kda_pattern, resources[resource]) and resource == \"kda\":\n",
    "                    resource_dict.update({\"kda\": resources[resource]})\n",
    "                if re.match(time_pattern, resources[resource]) and resource == \"game-time\":\n",
    "                    resource_dict.update({\"game-time\": resources[resource]})\n",
    "                if resource == \"creep-kill\":\n",
    "                    resource_dict.update({\"creep-kill\": resources[resource]})\n",
    "\n",
    "        if all(resource_dict.values()):\n",
    "            print(resource_dict)\n",
    "            is_analysed, text_bubble = add_analysis(resource_dict, position)\n",
    "            resource_dict = dict.fromkeys(resource_dict, None)\n",
    "\n",
    "        # print(is_analysed)\n",
    "        if is_analysed:\n",
    "            is_frame = False\n",
    "            analyzed_frame = sv.draw_image(resframe, text_bubble, .90, rect)\n",
    "            show_advice = True\n",
    "            return analyzed_frame\n",
    "        else:\n",
    "            is_frame = True\n",
    "            return resframe\n",
    "    else:\n",
    "        if show_advice == True:\n",
    "            if advice_timer<300:\n",
    "                analyzed_frame = sv.draw_image(frame, text_bubble, .90, rect)\n",
    "                advice_timer += 1\n",
    "                return analyzed_frame\n",
    "            else:\n",
    "                advice_timer = 0\n",
    "                show_advice = False\n",
    "\n",
    "        return frame\n",
    "\n",
    "def read_resources(frame, detections):\n",
    "    resources = {}\n",
    "    for i, det in enumerate(detections):\n",
    "        cls_name = det[-1][\"class_name\"]\n",
    "        #check if detected classes with necessary resources/metrics\n",
    "        if det[-1][\"class_name\"] in ocr_img_names:\n",
    "            # print(\"detections\", det[-1][\"class_name\"])\n",
    "            cropped_image = sv.crop_image(image=frame, xyxy=det[0])\n",
    "            ocr_result = reader.readtext(\n",
    "                cropped_image,\n",
    "                allowlist ='0123456789.:/',\n",
    "                mag_ratio=2.1,\n",
    "                min_size=13,\n",
    "            )  # easyocr\n",
    "\n",
    "            # print(\"ocr_result\", ocr_result)\n",
    "            for i2, ocr in enumerate(ocr_result):\n",
    "                if not ocr:\n",
    "                    text = 'none'\n",
    "                else:\n",
    "                    text = ocr\n",
    "                    if(text[-1] > 0.5): #check conf\n",
    "                        resources.update({cls_name : ocr[-2]})\n",
    "    return resources\n",
    "\n",
    "def add_analysis(resources, position=\"adc\" ):\n",
    "    kda = resources['kda']\n",
    "    game_time = resources['game-time']\n",
    "\n",
    "    if \".\" in game_time:\n",
    "        mins, seconds = map(int, game_time.split(\".\"))\n",
    "    else:\n",
    "        mins, seconds = map(int, game_time.split(\":\"))\n",
    "\n",
    "    question = (f\"game-time: {mins} minutes,\"\n",
    "                f\"Position: {position},\"\n",
    "                f\"kills/deaths/assists: {kda},\"\n",
    "                f\"cs: {resources['creep-kill']},\"\n",
    "                f\"Compare them to averages of their equivalent with the same position within similar game-time\")\n",
    "    retriever_question = f\"find from data game-time: {mins} minutes and position_{position}\"\n",
    "\n",
    "    answer = myLLm.generate(question, retriever_question)\n",
    "\n",
    "    text_bubble = add_text_bubble(answer, 20, max_width=400)\n",
    "\n",
    "    return True, text_bubble\n",
    "\n",
    "def format_kda(input_str):\n",
    "    # format kda for prompt\n",
    "    parts = input_str.split('/')\n",
    "\n",
    "    k, d, a = map(int, parts)\n",
    "\n",
    "    kills = str(k % 100).zfill(2)\n",
    "    deaths = str(d % 100).zfill(2)\n",
    "    assists = str(a % 100).zfill(2)\n",
    "\n",
    "    formatted_date = f\"{kills}/{deaths}/{assists}\"\n",
    "\n",
    "    return formatted_date"
   ],
   "id": "ef5a0f6d91ecb3ce",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:57:47.423094Z",
     "start_time": "2024-08-27T14:57:47.419739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Callable\n",
    "\n",
    "def process_video(\n",
    "        source_path: str,\n",
    "        target_path: str,\n",
    "        position: str,\n",
    "        callback: Callable[[np.ndarray, int], np.ndarray],\n",
    ") -> None:\n",
    "    source_video_info = sv.VideoInfo.from_video_path(video_path=source_path)\n",
    "    with sv.VideoSink(target_path=target_path, video_info=source_video_info) as sink:\n",
    "        for index, frame in enumerate(\n",
    "                sv.get_video_frames_generator(source_path=source_path)\n",
    "        ):\n",
    "            result_frame = callback(frame, index, position)\n",
    "            sink.write_frame(frame=result_frame)"
   ],
   "id": "9202ded871426f3f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:57:47.452728Z",
     "start_time": "2024-08-27T14:57:47.424101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, ttk\n",
    "\n",
    "class LeagueMachineApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"League Machine\")\n",
    "        self.root.geometry(\"900x350\")\n",
    "        self.root.resizable(0, 0)  # not resizable\n",
    "        self.root.configure(bg='black')\n",
    "        self.assets = \"assets/img\"\n",
    "        self.file_path = \"\"\n",
    "        # root.wm_attributes(\"-transparentcolor\", 'grey')\n",
    "\n",
    "        self.bg_image = tk.PhotoImage(file=f\"{self.assets}/league_machine_bg.png\")\n",
    "        self.bg_label = tk.Label(root, image=self.bg_image)\n",
    "        self.bg_label.place(relwidth=1, relheight=1)\n",
    "\n",
    "        self.title_label = tk.Label(root, text=\"League Machine\", font=(\"Helvetica\", 24), bg='black', fg='white')\n",
    "        self.title_label.pack(pady=10)\n",
    "\n",
    "        self.upload_button = tk.Button(root, text=\"Upload Video\", command=self.upload_video, bg='gray', fg='white')\n",
    "        self.upload_button.pack(pady=10)\n",
    "\n",
    "        self.position_label = tk.Label(root, text=\"Position\", bg='black', fg='white')\n",
    "        self.position_label.pack(pady=5)\n",
    "        self.position_var = tk.StringVar()\n",
    "        self.position_dropdown = ttk.Combobox(root, textvariable=self.position_var)\n",
    "        self.position_dropdown['values'] = (\"adc\", \"top\", \"midlane\", \"support\")\n",
    "        self.position_dropdown.pack(pady=5)\n",
    "\n",
    "        self.analyze_button = tk.Button(root, text=\"Analyze\", command=self.analyze, bg='gray', fg='white')\n",
    "        self.analyze_button.pack(pady=20)\n",
    "\n",
    "    def upload_video(self):\n",
    "        self.file_path = filedialog.askopenfilename()\n",
    "        print(f\"Video uploaded: {self.file_path}\")\n",
    "\n",
    "    # video prediction\n",
    "    def analyze(self):\n",
    "        position = self.position_var.get()\n",
    "        print(f\"Analyzing for position: {position} with filepath {self.file_path}\")\n",
    "        current_dateTime = datetime.now()\n",
    "        print(\"start Process Video\", is_frame, current_dateTime)\n",
    "        process_video(source_path=video_path, target_path=f\"vtemp.mp4\", callback=process_frame, position=position)\n",
    "        end_dateTime = datetime.now()\n",
    "        proc_time = end_dateTime - current_dateTime\n",
    "        print(\"End Process Video\", is_frame, \"end time:\", end_dateTime, \" processing Time: \", proc_time)\n",
    "        print(f\"Analysis complete\")"
   ],
   "id": "40ca8b07e177941f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:01:17.428223Z",
     "start_time": "2024-08-27T14:57:47.453742Z"
    }
   },
   "cell_type": "code",
   "source": [
    " # Load the YOLO model\n",
    "# model = YOLO(\"runsyolov8shires/detect/train31/weights/last.pt\")\n",
    "model = YOLO(\"runsyolov10shires/detect/train4/weights/last.pt\")\n",
    "\n",
    "# assets for the application\n",
    "video_path = \"clips/dl_gameplay_edited-fullgame.mp4\"\n",
    "image_path = \"screenshots/\"\n",
    "image_name = \"84_jpg.rf.3cbedbd35007e2d4fb1e75a3fa7ce16d\"\n",
    "img_path = \"assets/img/tbox_bg.png\"\n",
    "font_path = \"assets/fonts/Spiegel-TTF/Spiegel_TT_Regular.ttf\"\n",
    "#cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "byte_tracker = sv.ByteTrack()\n",
    "box_annotator = sv.BoundingBoxAnnotator()\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "trace_annotator = sv.TraceAnnotator()\n",
    "\n",
    "#load llm\n",
    "myLLm = llm.LeagueLLM()\n",
    "#specify a rectangular bounding box for analysis\n",
    "rect = sv.Rect(450,650,1000,330)\n",
    "#load ocr\n",
    "reader = easyocr.Reader(['en'], detect_network='craft', gpu=True)\n"
   ],
   "id": "d529781ead347771",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b3094e0f7ddd48f78ff5504ece94013b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:01:17.434406Z",
     "start_time": "2024-08-27T15:01:17.429226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#names of resources to read\n",
    "ocr_img_names = [\"player-champion\", \"kda\", \"game-time\", \"creep-kill\", \"player-gold\", \"ally-champion\"]\n",
    "advice_timer = 0\n",
    "show_advice = False\n",
    "text_bubble = None\n",
    "resource_dict = {\"kda\": None, \"game-time\": None, \"creep-kill\": None}\n",
    "required_resources = ['kda', 'creep-kill', 'game-time']\n",
    "kda_pattern = r'^\\d{1,2}/\\d{1,2}/\\d{1,2}$'\n",
    "time_pattern = r'^\\d{1,2}[:.]\\d{1,2}$'\n",
    "frame_interval = 9000\n",
    "is_frame = False"
   ],
   "id": "44aa0ac8c5ffd0b8",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T16:05:55.035522Z",
     "start_time": "2024-08-27T15:01:17.435411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "root = tk.Tk()\n",
    "app = LeagueMachineApp(root)\n",
    "root.mainloop()"
   ],
   "id": "f7be069acc59c8cb",
   "outputs": [],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
